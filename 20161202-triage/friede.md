## Yes

8 months
- Semi-supervised/adversarial learning --- embedding and autoencoders
- Reinforcement learning
- Conversational AI/bots w. a focus on either question answering (preferred) or
text generation (+ UX/character development)
- Automatic ML/parameter optimization

4 months
- Dynamic vocabs in NLP (fasttext)
- Time series/forecasting --- Gaussian processes (from a client perspective, a
report on time series would be very welcome)
- Interpretability (LIME, BRLs) and trust
- Source/fact credibility ranking --- fact-checking plugin but with a focus on
source reliability in a world without ground truth (a problem for crowd
sourcing efforts)

## Maybe

Slightly too early
- One shot learning
- Causal models and reasoning

Too specific
- Differential privacy/overfitting and private data --- synthetic data generation
- Source code repository analysis/sparse pointer models
- Provenance/reproducibility of data analysis

Not quite the right focus for FFL
- FPGAs

Not the most excited about it:
- Recommendation
- Anomaly detection
- Serverless products

## No

Not convinced this is good work (with the exception of use in RL context)
- Intuitive psychology/theory of mind (RL for coffee)

Too early (but I think these will be important topics in the long-term future)
- Automatic theorem proving/program correctness --- property-based code testing
- Neuromorphic computing
