## As interface:

https://experiments.withgoogle.com/ai/drum-machine/ - this drum machine experiment, where sounds are visualized using a t-SNE is the best example I’ve seen as using t-SNE as interface. It’s really interesting to think about why it works so well for this project and how that can and cannot generalize to other types of media and data. It works because the person putting together the beat cares more about the aural quality of the sound then anything else — like the source it came from. This won’t necessarily be true for other things — like books where the genre might be useful, or same author. The context of the sound is not important — in fact it could be distracting. I’m not exactly pinpointing what’s interesting about that. Another interesting thing: how does this differ from words? In words the context of the word makes up the meaning of the word… for the sound the waveform is all their really is. What would be the equivalent of the waveform for a word? Either the actual way it looks written out or the sound behind it. Those classifications would be interesting to see but not (I think) useful for creators, not beyond really experimental stuff. Kyle wrote more about how he thinks about creative t-SNE possibilities here: https://medium.com/@kcimc/a-return-to-machine-learning-2de3728558eb

http://encartopedia.fastforwardlabs.com/ - Sepand made this visualization of Wikipedia for us. I’d like to think how this could be even more useful as an interface. What if related articles showed up as a visualization? I’m not sure that would be much more helpful than a list. I think the most promising might be the visualization of the path you took through the topics. Could that be useful to help you understand your own research and thought process? Would you want to see other people’s paths like a playlist. I know when I’m feeling overwhelmed on a topic I often try to think of categorizing in visual terms, like if I place stuff in the right general space I feel like I have a handle on it. Part of the challenge would be: what if the t-SNE layout doesn’t match up with your own mental model? How could it still be a useful tool?

### Clarifying

Multi-dimensional data does not just occur in machine learning based projects. It is a longtime issue for visualizing data (roughly, any column in a table can be another dimension). The difference is connected to topic modeling with machine learning — the topics, or in this case dimensions, that the model selects (features) will probably not be intuitive to human. So, where in other multi-dimensional visualizations you might want to preserve certain dimensions, for the multi-dimensional machine learning stuff (like the recommendation system) you just want to approximate across all the dimensions. Though you might want to use something like color for genre to illuminate/check the clustering of the dimension reducing algorithm.
